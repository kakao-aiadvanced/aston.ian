{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#설치\n",
        "%%capture --no-stderr\n",
        "%pip install langchain_community langchainhub chromadb langchain langgraph tavily-python langchain-text-splitters langchain_openai"
      ],
      "metadata": {
        "id": "Fkl8TfCMFf8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from tavily import TavilyClient\n",
        "import os\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature = 0)\n",
        "\n",
        "#Tavily\n",
        "tavily = TavilyClient(api_key='')"
      ],
      "metadata": {
        "id": "B0yd8S3eFmob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE1mXRCmFbPQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pprint import pprint\n",
        "from typing import List, TypedDict\n",
        "\n",
        "from langchain_commTavilyClientunity.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import END, StateGraph\n",
        "from tavily import TavilyClient\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# INDEXING\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# ChromaDB를 사용한 벡터 저장소 생성\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "#  LangGraph Node 설정\n",
        "# -----------------------------------------------------------------\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    그래프의 상태를 나타냅니다.\n",
        "\n",
        "    Attributes:\n",
        "        question: 사용자의 질문\n",
        "        generation: LLM이 생성한 답변\n",
        "        documents: 검색된 문서 목록\n",
        "        retries: 답변 재시도 횟수\n",
        "        web_searched: 웹 검색 수행 여부 # MODIFIED: 웹 검색 루프 방지를 위한 상태 추가\n",
        "    \"\"\"\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[Document]\n",
        "    retries: int\n",
        "    web_searched: bool # MODIFIED\n",
        "\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"벡터 저장소에서 문서를 검색합니다.\"\"\"\n",
        "    print(\"--- 1. 문서 검색 (RETRIEVE) ---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = retriever.invoke(question)\n",
        "    print(f\"검색된 문서 수: {len(documents)}\")\n",
        "    # MODIFIED: 상태 초기화\n",
        "    return {\"documents\": documents, \"question\": question, \"retries\": 0, \"web_searched\": False}\n",
        "\n",
        "\n",
        "def grade_documents(state):\n",
        "    \"\"\"검색된 문서가 질문과 관련이 있는지 평가합니다.\"\"\"\n",
        "    print(\"--- 2. 관련성 확인 (GRADE DOCUMENTS) ---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
        "    If the document contains keywords related to the user question, grade it as relevant.\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
        "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"question: {question}\\n\\n document: {document} \"),\n",
        "    ])\n",
        "    retrieval_grader = prompt | llm | JsonOutputParser()\n",
        "\n",
        "    filtered_docs = []\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
        "        grade = score[\"score\"]\n",
        "        if grade.lower() == \"yes\":\n",
        "            print(\"  - GRADE: 문서 관련성 있음\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            print(\"  - GRADE: 문서 관련성 없음\")\n",
        "\n",
        "    state['documents'] = filtered_docs\n",
        "    return state\n",
        "\n",
        "\n",
        "def web_search(state):\n",
        "    \"\"\"Tavily를 사용하여 웹 검색을 수행합니다.\"\"\"\n",
        "    print(\"--- 4a. 웹 검색 (WEB SEARCH) ---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    print(f\"웹 검색 질의: {question}\")\n",
        "    response = tavily.search(query=question, max_results=3)\n",
        "    web_results = [\n",
        "        Document(\n",
        "            page_content=obj[\"content\"],\n",
        "            metadata={\"source\": obj[\"url\"], \"title\": obj[\"title\"]}\n",
        "        ) for obj in response['results']\n",
        "    ]\n",
        "    print(f\"웹 검색 결과 수: {len(web_results)}\")\n",
        "    state['documents'] = web_results\n",
        "    state['web_searched'] = True # MODIFIED: 웹 검색 수행 플래그 설정\n",
        "    return state\n",
        "\n",
        "\n",
        "def generate(state):\n",
        "    \"\"\"검색된 문서를 바탕으로 답변을 생성합니다.\"\"\"\n",
        "    print(\"--- 3. 답변 생성 (GENERATE) ---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    sources = \"\\n\".join([f\"Source URL: {doc.metadata.get('source', 'N/A')}, Title: {doc.metadata.get('title', 'N/A')}\" for doc in documents])\n",
        "\n",
        "    system = f\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
        "    If you don't know the answer, just say that you don't know.\n",
        "    Your final answer must include the sources (URL and title) provided below.\n",
        "\n",
        "    Sources:\n",
        "    {sources}\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Question: {question}\\n\\nContext: {context}\"),\n",
        "    ])\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    generation = rag_chain.invoke({\"context\": \"\\n\\n\".join([d.page_content for d in documents]), \"question\": question})\n",
        "    state[\"generation\"] = generation\n",
        "    return state\n",
        "\n",
        "\n",
        "def hallucination_checker(state):\n",
        "    \"\"\"생성된 답변에 환각(hallucination)이 있는지 평가합니다.\"\"\"\n",
        "    print(\"--- 5. 환각 확인 (HALLUCINATION CHECKER) ---\")\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    system = \"\"\"You are a grader assessing whether an answer is grounded in / supported by a set of facts.\n",
        "    Give a binary 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts.\n",
        "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Documents: {documents}\\n\\nAnswer: {generation}\"),\n",
        "    ])\n",
        "    hallucination_grader = prompt | llm | JsonOutputParser()\n",
        "\n",
        "    score = hallucination_grader.invoke({\"documents\": [d.page_content for d in documents], \"generation\": generation})\n",
        "    grade = score[\"score\"]\n",
        "\n",
        "    if grade == \"yes\":\n",
        "        print(\"  - CHECK: 환각 없음. 답변 완료.\")\n",
        "        return \"useful\"\n",
        "    else:\n",
        "        print(\"  - CHECK: 환각 감지. 재시도.\")\n",
        "        state[\"retries\"] = state.get(\"retries\", 0) + 1\n",
        "        return \"not_supported\"\n",
        "\n",
        "\n",
        "def handle_failure(state):\n",
        "    \"\"\"관련성 또는 환각 문제로 실패 시 처리합니다.\"\"\"\n",
        "    print(\"--- 최종 실패 처리 ---\")\n",
        "    retries = state.get(\"retries\", 0)\n",
        "    web_searched = state.get(\"web_searched\", False)\n",
        "\n",
        "    if not state.get(\"documents\") and web_searched:\n",
        "        generation = \"failed: not relevant\"\n",
        "    elif retries >= 1:\n",
        "        generation = \"failed: hallucination\"\n",
        "    else:\n",
        "        generation = \"failed: unknown error\"\n",
        "\n",
        "    return {\"generation\": generation}\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# LangGraph 엣지 (흐름 제어) 정의\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"문서의 관련성 여부에 따라 답변 생성 또는 웹 검색으로 분기합니다.\"\"\"\n",
        "    print(\"--- 2a. 관련성 기반 분기 ---\")\n",
        "    web_searched = state.get(\"web_searched\", False)\n",
        "\n",
        "    if not state.get(\"documents\"):\n",
        "        if web_searched:\n",
        "            # MODIFIED: 웹 검색을 이미 했는데도 관련 문서가 없으면 실패 처리\n",
        "            print(\"  - DECISION: 웹 검색 후에도 관련 문서 없음 -> 실패 처리로 이동\")\n",
        "            return \"failure\"\n",
        "        else:\n",
        "            # MODIFIED: 관련 문서가 없으면 웹 검색으로 이동\n",
        "            print(\"  - DECISION: 관련 문서 없음 -> 웹 검색으로 이동\")\n",
        "            return \"web_search\"\n",
        "    else:\n",
        "        print(\"  - DECISION: 관련 문서 있음 -> 답변 생성으로 이동\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "def check_hallucination_and_retry(state):\n",
        "    \"\"\"환각 여부 및 재시도 횟수에 따라 분기합니다.\"\"\"\n",
        "    print(\"--- 5a. 환각 기반 분기 ---\")\n",
        "    decision = hallucination_checker(state)\n",
        "    retries = state.get(\"retries\", 0)\n",
        "\n",
        "    if decision == \"useful\":\n",
        "        return \"end\"\n",
        "    elif retries < 1:\n",
        "        print(f\"  - 재시도 횟수: {retries}. 답변 재생성.\")\n",
        "        return \"retry\"\n",
        "    else:\n",
        "        print(f\"  - 재시도 횟수: {retries}. 실패 처리.\")\n",
        "        return \"failure\"\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# build\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# 노드 추가\n",
        "workflow.add_node(\"retrieve\", retrieve)\n",
        "workflow.add_node(\"grade_documents\", grade_documents)\n",
        "workflow.add_node(\"web_search\", web_search)\n",
        "workflow.add_node(\"generate\", generate)\n",
        "workflow.add_node(\"handle_failure\", handle_failure)\n",
        "\n",
        "# 엣지(흐름) 설정\n",
        "workflow.set_entry_point(\"retrieve\") # MODIFIED: 시작점을 retrieve로 변경\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"generate\": \"generate\",\n",
        "        \"failure\": \"handle_failure\", # MODIFIED: 실패 경로 추가\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"web_search\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    check_hallucination_and_retry,\n",
        "    {\n",
        "        \"retry\": \"generate\",\n",
        "        \"failure\": \"handle_failure\",\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"handle_failure\", END)\n",
        "\n",
        "# 그래프 컴파일\n",
        "app = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Case 1: Vector Store에 관련 정보가 있는 경우\n",
        "print(\"\\n\\n--- [Test Case 1] 실행: 'What is prompt?' ---\\n\")\n",
        "inputs = {\"question\": \"What is prompt?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint(f\"노드: {key}\")\n",
        "pprint(f\"최종 답변:\\n{value['generation']}\")\n",
        "\n",
        "\n",
        "# Test Case 2: Vector Store에 관련 정보가 없어 웹 검색을 수행하는 경우\n",
        "print(\"\\n\\n--- [Test Case 2] 실행: 'What is KAKAO CORP?' ---\\n\")\n",
        "inputs = {\"question\": \"What is KAKAO CORP?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint(f\"노드: {key}\")\n",
        "pprint(f\"최종 답변:\\n{value['generation']}\")\n",
        "\n",
        "# Test Case 3: 웹 검색 후에도 관련 정보가 없는 경우 (Tavily 검색어 조정)\n",
        "print(\"\\n\\n--- [Test Case 3] 실행: '96125m600' ---\\n\")\n",
        "inputs = {\"question\": \"asdlfkjasdlfkjaskldfj\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint(f\"노드: {key}\")\n",
        "pprint(f\"최종 답변:\\n{value['generation']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so4TPZ5lF_uv",
        "outputId": "b66169a3-b08f-4df4-cb14-44632d45154d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- [Test Case 1] 실행: 'What is prompt?' ---\n",
            "\n",
            "--- 1. 문서 검색 (RETRIEVE) ---\n",
            "검색된 문서 수: 4\n",
            "'노드: retrieve'\n",
            "--- 2. 관련성 확인 (GRADE DOCUMENTS) ---\n",
            "  - GRADE: 문서 관련성 있음\n",
            "  - GRADE: 문서 관련성 있음\n",
            "  - GRADE: 문서 관련성 있음\n",
            "  - GRADE: 문서 관련성 있음\n",
            "--- 2a. 관련성 기반 분기 ---\n",
            "  - DECISION: 관련 문서 있음 -> 답변 생성으로 이동\n",
            "'노드: grade_documents'\n",
            "--- 3. 답변 생성 (GENERATE) ---\n",
            "--- 5a. 환각 기반 분기 ---\n",
            "--- 5. 환각 확인 (HALLUCINATION CHECKER) ---\n",
            "  - CHECK: 환각 없음. 답변 완료.\n",
            "'노드: generate'\n",
            "('최종 답변:\\n'\n",
            " 'A prompt is a sequence of prefix tokens that increases the probability of '\n",
            " 'obtaining a desired output given an input. These prompts can be treated as '\n",
            " 'trainable parameters and optimized directly in the embedding space using '\n",
            " 'techniques like gradient descent. Various methods such as AutoPrompt, '\n",
            " 'Prefix-Tuning, P-tuning, and Prompt-Tuning have been developed to enhance '\n",
            " 'the effectiveness of prompts in generating outputs. Additionally, Automatic '\n",
            " 'Prompt Engineering (APE) is a method that searches through model-generated '\n",
            " 'instruction candidates and selects the best one based on a scoring '\n",
            " 'function.\\n'\n",
            " '\\n'\n",
            " 'For more details, you can refer to the source: [Prompt Engineering | '\n",
            " \"Lil'Log](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/).\")\n",
            "\n",
            "\n",
            "--- [Test Case 2] 실행: 'What is KAKAO CORP?' ---\n",
            "\n",
            "--- 1. 문서 검색 (RETRIEVE) ---\n",
            "검색된 문서 수: 4\n",
            "'노드: retrieve'\n",
            "--- 2. 관련성 확인 (GRADE DOCUMENTS) ---\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "--- 2a. 관련성 기반 분기 ---\n",
            "  - DECISION: 관련 문서 없음 -> 웹 검색으로 이동\n",
            "'노드: grade_documents'\n",
            "--- 4a. 웹 검색 (WEB SEARCH) ---\n",
            "웹 검색 질의: What is KAKAO CORP?\n",
            "웹 검색 결과 수: 3\n",
            "'노드: web_search'\n",
            "--- 2. 관련성 확인 (GRADE DOCUMENTS) ---\n",
            "  - GRADE: 문서 관련성 있음\n",
            "  - GRADE: 문서 관련성 있음\n",
            "  - GRADE: 문서 관련성 있음\n",
            "--- 2a. 관련성 기반 분기 ---\n",
            "  - DECISION: 관련 문서 있음 -> 답변 생성으로 이동\n",
            "'노드: grade_documents'\n",
            "--- 3. 답변 생성 (GENERATE) ---\n",
            "--- 5a. 환각 기반 분기 ---\n",
            "--- 5. 환각 확인 (HALLUCINATION CHECKER) ---\n",
            "  - CHECK: 환각 없음. 답변 완료.\n",
            "'노드: generate'\n",
            "('최종 답변:\\n'\n",
            " 'Kakao Corp, also known as Kakao Corporation, is a South Korean internet '\n",
            " 'conglomerate headquartered in Jeju City. It was formed through the merger of '\n",
            " 'Daum Communications and is known for providing a wide range of digital '\n",
            " 'services, including digital communication, financial services, and mobility '\n",
            " 'solutions. The company operates various platforms and services such as Kakao '\n",
            " 'Talk, Kakao Pay, Kakao Bank, and Kakao Mobility, among others.\\n'\n",
            " '\\n'\n",
            " 'Sources:\\n'\n",
            " '- [Kakao - Wikipedia](https://en.wikipedia.org/wiki/Kakao)\\n'\n",
            " '- [Kakao Corp: Overview - '\n",
            " 'GlobalData](https://www.globaldata.com/company-profile/kakao-corp/)\\n'\n",
            " '- [Kakao - 카카오](https://www.kakaocorp.com/page/?lang=en)')\n",
            "\n",
            "\n",
            "--- [Test Case 3] 실행: '96125m600' ---\n",
            "\n",
            "--- 1. 문서 검색 (RETRIEVE) ---\n",
            "검색된 문서 수: 4\n",
            "'노드: retrieve'\n",
            "--- 2. 관련성 확인 (GRADE DOCUMENTS) ---\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "--- 2a. 관련성 기반 분기 ---\n",
            "  - DECISION: 관련 문서 없음 -> 웹 검색으로 이동\n",
            "'노드: grade_documents'\n",
            "--- 4a. 웹 검색 (WEB SEARCH) ---\n",
            "웹 검색 질의: asdlfkjasdlfkjaskldfj\n",
            "웹 검색 결과 수: 3\n",
            "'노드: web_search'\n",
            "--- 2. 관련성 확인 (GRADE DOCUMENTS) ---\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "  - GRADE: 문서 관련성 없음\n",
            "--- 2a. 관련성 기반 분기 ---\n",
            "  - DECISION: 웹 검색 후에도 관련 문서 없음 -> 실패 처리로 이동\n",
            "'노드: grade_documents'\n",
            "--- 최종 실패 처리 ---\n",
            "'노드: handle_failure'\n",
            "'최종 답변:\\nfailed: not relevant'\n"
          ]
        }
      ]
    }
  ]
}
